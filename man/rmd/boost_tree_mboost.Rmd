```{r, child = "setup.Rmd", include = FALSE}
```

`r descr_models("boost_tree", "mboost")`

## Tuning Parameters

```{r mboost-param-info, echo = FALSE}
defaults <- 
  tibble::tibble(parsnip = c("mtry", "trees", "tree_depth", "min_n", "loss_reduction"),
                 default = c("see below", "100L", "2L", "10L", "0"))

param <-
  boost_tree() %>% 
  set_engine("mboost") %>% 
  set_mode("censored regression") %>%
  tunable() %>% 
  dplyr::select(-source, -component, -component_id, parsnip = name) %>% 
  dplyr::mutate(
    dials = purrr::map(call_info, get_dials),
    label = purrr::map_chr(dials, ~ .x$label),
    type = purrr::map_chr(dials, ~ .x$type)
  ) %>% 
  dplyr::inner_join(defaults, by = "parsnip") %>% 
  dplyr::mutate(
    item = 
      glue::glue("- `{parsnip}`: {label} (type: {type}, default: {default})\n\n")
  )
```

This model has `r nrow(param)` tuning parameters:

```{r mboost-param-list, echo = FALSE, results = "asis"}
param$item
```

The `mtry` parameter is related to the number of predictors. The default is to use all predictors.

## Translation from parsnip to the original package (censored regression)

```{r mboost-creg}
boost_tree() %>% 
  set_engine("mboost") %>% 
  set_mode("censored regression") %>% 
  translate()
```

[blackboost_train()] is a wrapper around [mboost::blackboost()] (and other functions) that makes it easier to run this model. 

## Preprocessing requirements

```{r child = "template-tree-split-factors.Rmd"}
```

## References

 - Buehlmann P, Hothorn T. 2007. Boosting algorithms: regularization, prediction and model fitting. _Statistical Science_, 22(4), 477â€“505.

 - Kuhn, M, and K Johnson. 2013. _Applied Predictive Modeling_. Springer.
